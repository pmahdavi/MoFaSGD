#!/bin/tcsh
#PBS -l ngpus=2
#PBS -l ncpus=16
#PBS -l walltime=16:00:00
#PBS -q workq@e5-cse-cbgpu01.eecscl.psu.edu
#PBS -N pt
#PBS -M pxm5426@psu.edu 
#PBS -m bea
#PBS -l mem=60g
#PBS -o pbs_results/
#PBS -e pbs_results/
cd $PBS_O_WORKDIR

source ~/.tcshrc

conda activate n-gpt2

# Run with all parameters now that we've fixed the filtering
python run.py --optimizer muon --num-gpus 2 \
  --config '{"lr": 0.05, "momentum": 0.95, "nesterov": true, "ns_steps": 5, "scheduler_name": "original", "cooldown_frac": 0.4}' \
  --mem-prof --mem-start-step 20 --mem-end-step 23


#python run.py --optimizer lomuon  --num-gpus 2 --config '{"lr": 0.0008, "eta1": 0.25, "eta2": 0.0, "rank": 32, "beta": 0.95, "use_current_projection": true, "use_ones_for_nonzero_s": false, "warmup_steps": 600, "beta_start": 0.65, "beta_end": 0.85, "eps": 1e-6, "max_value": 1000, "cooldown_frac": 0.8}'

#python run.py --optimizer galore --num-gpus 4 --config '{"lr": 0.01, "weight_decay": 0.0, "group_params": {"rank": 32, "update_proj_gap": 150, "scale": 0.25, "proj_type": "std"}}'

# python run.py --optimizer lomuon --num-gpus 2 \
#   --config '{"lr": 0.01, "eta1": 0.25, "eta2": 0.0, "rank": 32, "beta": 0.95, "use_current_projection": true, "use_ones_for_nonzero_s": false, "warmup_steps": 300, "beta_start": 0.65, "beta_end": 0.85, "eps": 1e-4, "max_value": 100}' \
#   --mem-prof --mem-start-step 20 --mem-end-step 23
